---
title: "Tres consideraciones importantes sobre el Valor P"
author: "Bryan Rodr√≠guez-Murillo"
date: "2020-10-15"
description: 
images:
- img\banco_imagenes\p-value.png
tags:
- ciencia de datos
- laboral
- estad√≠stica
output: html_document
categories: ["Blog"]
---

<style>
body {
text-align: justify}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

Desde que Fisher propusiera el test de significancia en 1925, el Valor P se convirti√≥ en la medida de decisi√≥n m√°s ampliamente usada en la estad√≠stica inferencial; son incontables los trabajos cient√≠ficos que basan sus conclusiones en esta herramienta estad√≠stica, mientras la academia a veces ense√±a su uso **sin considerar sus alternativas‚Ä¶ o sus riesgos**.

Por ello, me sorprend√≠ mucho al enterarme que, en efecto, el Valor P no es siempre la v√≠a deductiva m√°s recomendable e requiere tomar en cuenta varias consideraciones importantes que no se ense√±an en las clases de estad√≠stica, consideraciones que han llevado a retractarse a m√°s de un cient√≠fico -dicen las malas lenguas :tongue:-. 

Muchos de mis compa√±eros del Tec hoy trabajan en empresas donde inferencia estad√≠stica es crucial, como las de dispositivos m√©dicos o electr√≥nicos; con la cual resulta m√°s que evidente la importancia de las siguientes *3 consideraciones sobre el Valor P*.

## 1. ¬øQu√© es y qu√© NO es el Valor P?

Al realizar deducciones estad√≠sticas NO hay escapatoria: debemos tener muy claros los conceptos -por aburrido o dif√≠cil que resulte- si no queremos caer en interpretaciones enga√±osas. Para colmo, con el Valor P se afirma que "hay mucha confusi√≥n entre los investigadores" (Masters, 2020). Si se va a realizar un trabajo que involucra un test de significancia, no vendr√≠a mal estar claro con el concepto:

> "Es la probabilidad de obtener un 'resultado' de prueba de hip√≥tesis al menos tan extremo como el calculado a partir de la muestra y la distribuci√≥n escogida, si se asume que la hip√≥tesis nula es verdadera", (definici√≥n construida a partir de varias fuentes).

La √∫ltima parte es crucial, **las pruebas de hip√≥tesis son pruebas de descarte**: si el Valor P es bajo (m√°s bajo que el nivel de significancia) esto significa que un "resultado" como el obtenido (as√≠ de extremo o m√°s extremo) es muy poco probable bajo las condiciones dadas, por lo cu√°l descartamos que la hip√≥tesis nula sea verdadera. 

¬øY a qu√© hago referencia con "el resultado"? Las pruebas de hip√≥tesis usan estad√≠sticos de prueba, valores "calculados a partir de la muestra y la distribuci√≥n escogidas". No entrar√© m√°s en detalle para no confundir; pero, recomiendo consultar **[este post en Towards Data Science, s√∫per ilustrativo.](https://towardsdatascience.com/p-values-explained-by-data-scientist-f40a746cfc8)**

No obstante lo anterior, para muchos la mejor definici√≥n es una lista de todo lo que NO estamos hablando. As√≠ que, **[con base en el blog de un estad√≠stico brit√°nico](https://towardsdatascience.com/the-significant-problems-of-p-values-c31b2b6ed275)**, enlisto una serie de concepciones usuales y **ERRADAS** del Valor P:

* El Valor P NO es la probabilidad de que la hip√≥tesis nula sea verdadera: El Valor P ASUME que la hip√≥tesis nula es verdadera, mas no es la probabilidad de esta.
* El valor P NO es la probabilidad de que el resultado obtenido de la prueba se produzca por azar.
* El Nivel de Significancia convencional de 5% es, valga la redundancia, una convenci√≥n. Por ende, no tiene nada que ver con el Valor P en realidad.
* El Valor P NO es el tama√±o o importancia del efecto (esto ser√≠a el coeficiente del modelo matem√°tico asociado a la prueba aplicada)

## 2. Los grados de libertad del experimentador

Los autores Simmons, Nelson & Simonsohn (2011) acu√±aron **[en este art√≠culo](https://journals.sagepub.com/doi/full/10.1177/0956797611417632)** el concepto **Grados de Libertad del Experimentador**, el cu√°l hace referencia a decisiones que un investigador debe tomar al recolectar, analizar y reportar datos, las cu√°les pueden determinar el resultado de un test de significancia. 

Resulta que los investigadores suelen querer rechazar la hip√≥tesis nula, o dicho en otras palabras: **suelen querer demostrar un efecto**. Un ejemplo t√≠pico de mi carrera ser√≠a el de ingenieros dise√±adores queriendo demostrar que el nuevo producto que desarrollaron tiene un mejor desempe√±o que el producto "viejo" de la empresa; un ejemplo m√°s cl√°sico podr√≠a ser el de cient√≠ficos de una farmac√©utica queriendo probar que cierta droga experimental s√≠ tiene efectos beneficiosos (por ejemplo, las vacunas contra el coronavirus :grimacing:).

Por ende (seg√∫n el art√≠culo :point_up:), algunas de las siguientes decisiones podr√≠an tomarse con la intensi√≥n de rechazar la hip√≥tesis nula:

* ser flexible al escoger
  * entre variables dependientes,
  * el tama√±o de muestra,
  * usar covariadas o
  * reportar solo parte de las condiciones del experimento.

La consecuencia de esto es que la probabilidad de un falso positivo (el error tipo 1: *la probabilidad de rechazar la hip√≥tesis nula cuando en realidad es verdadera*) ser√° mayor que el alfa reportado. 

<center>

![Tomado de: http://agroecologiavenezuela.blogspot.com/2008/03/sobre-la-importancia-relativa-del-error.html](tabla_de_errores estad√≠sticos.jpg)

</center>

¬øY qu√© tiene que ver esto con el Valor P? Pues, en mi opini√≥n, si un investigador centra pensamiento solamente en correr el test de significancia, probablemente cometa el error de pensar que el resultado del Valor P es incuestionable, que es objetivo "por defecto" o que es el fin de toda la investigaci√≥n.

**El Valor P no es lo m√°s importante de una investigaci√≥n o de la estad√≠stica inferencial** :sweat_smile:; pero, adem√°s, resulta que en ciertas situaciones sus conclusiones pueden ser enga√±osas :ghost:.

> "Rather, it is common (and accepted practice) for researchers to explore various analytic alternatives, to search for a combination that yields 'statistical significance', and to then report only what 'worked'. The problem, of course, is that the likelihood of at least one (of many) analyses producing a falsely positive finding at the 5% level is necessarily greater than 5%",
> Simmons, Nelson & Simonsohn (2011).

## 3. Valor P, Simulaci√≥n y Big Data

Seguramente todos los que hemos recibido alguna clase de Estad√≠stica hemos escuchado algo como esto, al menos una vez: *es muy dif√≠cil, sino imposible, estudiar toda una poblaci√≥n; esta es la gran ventaja de la estad√≠stica inferencial: que se puede estudiar una muestra y generalizar las conclusiones a toda la poblaci√≥n*; sin embargo, con la llegada del Big Data, esa  ventaja puede que haya desaparecido en ciertos casos.

Por otro lado, la Simulaci√≥n (o m√©todos con el Bootstrap) nos permiten replicar datos masivamente sobre el comportamiento de cierto sistema (comportamiento establecido ‚Äìcomo no- por medio de la estad√≠stica inferencial).

Las personas que han trabajado alguna vez con datos masivos ya lo saben: **los test de significancia dan resultados extra√±os** y usualmente siempre se termina rechazando la hip√≥tesis nula. **[En este art√≠culo de la IEEE](https://ieeexplore.ieee.org/document/7408210)**, el autor (Hoffman, 2015) presenta cuatro ejemplos en los que se aplica una prueba t de medias y que evidencian por qu√© no es aconsejable usar el Valor P al estudiar datos masivos. Ve√°moslos:

<center>

![Tomado de Hoffman, 2015](cuadro_t_test.png)

</center>

#### 1) Ejemplo t√≠pico de libro

En el primer ejemplo se tienen dos tama√±os de muestra moderadamente grandes, lo suficiente para cualquier m√©todo de estad√≠stica inferencial. Ya que la variabilidad entre las muestras es similar y peque√±a, y adem√°s la diferencia entre medias es considerable, el Valor P es bajo, lo suficiente para descartar la hip√≥tesis nula.

<center>

![*Comportamiento esperado para el tama√±o de muestra dado versus la realidad, desde el punto de vista de la estad√≠stica inferencial*](caso_tipico_libro.png)

</center>

#### 2) Validando resultados de una simulaci√≥n.

El segundo ejemplo presenta diferencias enormes entre los tama√±os de las muestras a comparar. Pi√©nsese en un ingeniero de procesos que quiere validar los resultados obtenidos de una Simulaci√≥n (n = 10^3), para ello toma una muestra del sistema real (n = 25) y aplica la prueba t.

Ya que la muestra peque√±a tiene mucha variabilidad y muy pocos datos en comparaci√≥n con la simulaci√≥n, si dicha simulaci√≥n es fiel a la realidad, uno podr√≠a pensar que no hay suficiente evidencia para concluir que las medias son significativamente diferentes. Sin embargo, el Valor P resulta menor que el nivel de significancia. No es posible validar estad√≠sticamente la simulaci√≥n y **quiz√° esta conclusi√≥n est√© desacertada**.

#### 3) Muchos datos en ambas muestras

¬øQu√© tal si ambas muestras son masivas? Vemos en el ejemplo una variabilidad muy alta en ambas muestras y la diferencia entre las medias es √≠nfima en comparaci√≥n con la variabilidad.

He escuchado a cient√≠ficos de datos decir que *"con Big Data todo es significativo"*, aludiendo a que los datos masivos son en realidad muy variables, que de todo pasa y nada es descartable.No obstante y contra cualquier pron√≥stico, para la prueba t las medias son estad√≠sticamente diferentes (con una diferencia de s√≥lo una unidad y apesar de la variabilidad :confounded::-1:).

<center>

![*Comportamiento esperado para el tama√±o de muestra dado versus la realidad, desde el punto de vista de la estad√≠stica inferencial*](caso_datos_masivos.png)

</center>

#### 4) Pocos datos en ambas muestras :unamused:

El caso opuesto al ejemplo anterior nos termina de mostrar cuan enga√±osas pueden ser las conclusiones con el Valor P. 

Supongamos que se est√° estudiando exactamente el mismo fen√≥meno que del ejemplo anterior, s√≥lo que en este caso recogemos muy pocos datos para ambas muestras. A pesar que la variabilidad es grande (casi id√©ntica a la del primer ejemplo) y que la diferencia entre medias es considerablemente grande tambi√©n, la prueba t dictamina que no hay diferencias significativas.

Bien afirma Hoffman que, en este tipo de aplicaciones, usar el Valor P como medida de decisi√≥n no es confiable. Por ende, se recomienda usar otras medidas, espec√≠ficamente los intervalos de confianza y el tama√±o de los efectos (para m√°s informaci√≥n consultar el art√≠culo).

## Conclusi√≥n

¬øQu√© nos ense√±an estas tres consideraciones? Creo que lo m√°s importante, lo que a muchos se nos olvida, es que los test estad√≠sticos -y en general la estad√≠stica inferencial- son herramientas cient√≠ficas: **siempre que dejen de estar orientados a la objetividad (con o sin querer) pierden su raz√≥n de ser**.  

> "Por decadas, metod√≥logos estad√≠sticos destacados han argumentado que enfocarse en Valores P no propicia la ciencia, y que estas pruebas son malinterpretadas con regularidad", Hofmann (2015).

<center>

-o-

</center>

> "Nuestra objetivo como cient√≠ficos no es publicar tantos articulos como sea posible, sino m√°s bien descubrir y difundir la verdad", Simmons, Nelson y Simonsohn (2011)

Gracias por leer este publicaci√≥n. Dame tus comentarios a trav√©s de mis redes sociales. Nos leemos luego üòâ .

